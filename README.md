# ğŸ™ï¸ NIRA â€“ Voice-Based AI Assistant for Analytas

NIRA is a professional **AI voice assistant** built using **LangChain, Whisper, Groq LLM, and FAISS**, designed to provide accurate and conversational responses based solely on the **Agenta documentation**.  
It records speech, transcribes it to text, retrieves the most relevant information, and speaks back the answer in a clear, natural human-like voice.

---

## ğŸš€ Features

- ğŸ§ **Voice Interaction:** Speak to NIRA using your microphone.  
- ğŸ§  **Intelligent Retrieval:** Uses LangChain + FAISS to fetch accurate information from Agenta docs.  
- ğŸ’¬ **Contextual Responses:** Powered by Groq LLM for smart, structured answers.  
- ğŸ”Š **Natural TTS Output:** Converts responses to speech using Google TTS and Pydub.  
- ğŸ“ **Automatic Transcription:** Whisper converts your voice input into text with high accuracy.  
- âš™ï¸ **Keyboard Control:** Press keys to start/stop recording or end the session.  

---

## ğŸ§© Tech Stack

- **LLM Backend:** Groq LLM (`gpt-oss-120b`)  
- **Vector Store:** FAISS with HuggingFace Embeddings  
- **Audio Processing:** PyAudio, SoundDevice, Pydub  
- **Speech Models:** Whisper (OpenAI), gTTS  
- **Frameworks:** LangChain, dotenv  
- **Documentation Source:** [Agenta Docs](https://docs.agenta.ai/)

---

## ğŸ› ï¸ Setup & Installation

### 1ï¸âƒ£ Clone the Repository
```bash
git clone https://github.com/<your-username>/nira-voice-assistant.git
cd nira-voice-assistant
```

### 2ï¸âƒ£ Create a Virtual Environment
```bash
python -m venv venv
venv\Scripts\activate  # on Windows
source venv/bin/activate  # on macOS/Linux
```

### 3ï¸âƒ£ Install Dependencies
```bash
pip install -r requirements.txt
```

### 4ï¸âƒ£ Create a `.env` File
Create a `.env` file in the root folder and add:
```
GROQ_API_KEY=your_api_key_here
```

---

## ğŸ¤ Usage

1. Run the script:
   ```bash
   python nira.py
   ```

2. When prompted:
   - Press **`y`** â†’ Start a voice session  
   - Press **`s`** â†’ Start recording your question  
   - Press **`e`** â†’ Stop recording  
   - Press **`q`** â†’ Quit the program  

3. NIRA will:
   - Transcribe your speech using **Whisper**
   - Retrieve the most relevant content from **Agenta Docs**
   - Generate a professional response using **Groq LLM**
   - Speak the response aloud via **Google TTS**

---

## ğŸ“‚ Project Structure

```
nira/
â”‚
â”œâ”€â”€ nira.py                  # Main script
â”œâ”€â”€ audio/                   # Stores input/output audio
â”œâ”€â”€ .env                     # Environment variables (API key)
â”œâ”€â”€ requirements.txt          # Dependencies
â””â”€â”€ README.md                # Documentation
```

---

## âš¡ Future Improvements

- Add streaming responses for real-time conversations  
- Support multi-language voice input/output  
- Deploy NIRA as a web app using Streamlit or FastAPI  

---

## ğŸ™ Acknowledgements

- [LangChain](https://www.langchain.com/)  
- [Whisper by OpenAI](https://github.com/openai/whisper)  
- [Groq Cloud](https://groq.com/)  
- [FAISS](https://github.com/facebookresearch/faiss)  
- [Agenta Docs](https://docs.agenta.ai/)

---

**ğŸ’¡ Author:** [Vinay Lakkimsetti]  
**ğŸ“… Year:** 2025  
**ğŸ”— Repository:** [GitHub Repo Link]
